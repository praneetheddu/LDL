{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praneetheddu/LDL/blob/main/tutorials/MNIST_DLL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training using Tensorflow and MNIST\n"
      ],
      "metadata": {
        "id": "oTj_ntBhRITO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n4hbQv5uMEIH"
      },
      "outputs": [],
      "source": [
        "# TF imports\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Python imports\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "# only print out errors and supress warnings\n",
        "tf.get_logger().setLevel(logging.ERROR) \n",
        "tf.random.set_seed(7) # Reproducable randomness\n",
        "\n",
        "# Hyper params\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAFDCb-gOjeH",
        "outputId": "5c63312a-cf07-444e-a30e-bae07ccdd159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load mnist dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Standardize the test dataset\n",
        "mean = np.mean(train_images)\n",
        "stddev = np.std(train_images)\n",
        "train_images = (train_images - mean) / stddev\n",
        "test_images = (test_images - mean) / stddev\n",
        "\n",
        "# one hot enccoding\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "test_labels = to_categorical(test_labels, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gVFgq2jHP6Aa"
      },
      "outputs": [],
      "source": [
        "# Initialize weights\n",
        "initializer = keras.initializers.RandomUniform(minval = -0.1, maxval = 0.1)\n",
        "'''\n",
        "Create Sequential models Fully Connected Model\n",
        "- 2 layers: hidden and output layer\n",
        "Input Layer = 784 inputs flattened by 28 x 288 image + 1 bias input \n",
        "Hidden Layer = 25 Inputs\n",
        "Output Layer = 10 Inputs \n",
        "'''\n",
        "model = keras.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(25, activation='tanh',\n",
        "                          kernel_initializer=initializer,\n",
        "                          bias_initializer='zeros'),\n",
        "        keras.layers.Dense(10, activation='sigmoid',\n",
        "                          kernel_initializer=initializer,\n",
        "                          bias_initializer='zeros')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMAu2NMTSSeL",
        "outputId": "a66b4af1-6a38-442b-9258-6bd2890f3311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 - 84s - loss: 0.0526 - accuracy: 0.7047 - val_loss: 0.0266 - val_accuracy: 0.8893 - 84s/epoch - 1ms/step\n",
            "Epoch 2/20\n",
            "60000/60000 - 71s - loss: 0.0217 - accuracy: 0.8960 - val_loss: 0.0176 - val_accuracy: 0.9107 - 71s/epoch - 1ms/step\n",
            "Epoch 3/20\n",
            "60000/60000 - 69s - loss: 0.0166 - accuracy: 0.9112 - val_loss: 0.0152 - val_accuracy: 0.9181 - 69s/epoch - 1ms/step\n",
            "Epoch 4/20\n",
            "60000/60000 - 69s - loss: 0.0147 - accuracy: 0.9193 - val_loss: 0.0140 - val_accuracy: 0.9219 - 69s/epoch - 1ms/step\n",
            "Epoch 5/20\n",
            "60000/60000 - 71s - loss: 0.0135 - accuracy: 0.9238 - val_loss: 0.0132 - val_accuracy: 0.9253 - 71s/epoch - 1ms/step\n",
            "Epoch 6/20\n",
            "60000/60000 - 71s - loss: 0.0127 - accuracy: 0.9281 - val_loss: 0.0125 - val_accuracy: 0.9270 - 71s/epoch - 1ms/step\n",
            "Epoch 7/20\n",
            "60000/60000 - 68s - loss: 0.0121 - accuracy: 0.9313 - val_loss: 0.0121 - val_accuracy: 0.9304 - 68s/epoch - 1ms/step\n",
            "Epoch 8/20\n",
            "60000/60000 - 69s - loss: 0.0117 - accuracy: 0.9335 - val_loss: 0.0117 - val_accuracy: 0.9296 - 69s/epoch - 1ms/step\n",
            "Epoch 9/20\n",
            "60000/60000 - 70s - loss: 0.0112 - accuracy: 0.9357 - val_loss: 0.0115 - val_accuracy: 0.9315 - 70s/epoch - 1ms/step\n",
            "Epoch 10/20\n",
            "60000/60000 - 69s - loss: 0.0109 - accuracy: 0.9373 - val_loss: 0.0114 - val_accuracy: 0.9323 - 69s/epoch - 1ms/step\n",
            "Epoch 11/20\n",
            "60000/60000 - 69s - loss: 0.0106 - accuracy: 0.9387 - val_loss: 0.0112 - val_accuracy: 0.9338 - 69s/epoch - 1ms/step\n",
            "Epoch 12/20\n",
            "60000/60000 - 70s - loss: 0.0104 - accuracy: 0.9400 - val_loss: 0.0110 - val_accuracy: 0.9338 - 70s/epoch - 1ms/step\n",
            "Epoch 13/20\n",
            "60000/60000 - 69s - loss: 0.0101 - accuracy: 0.9410 - val_loss: 0.0107 - val_accuracy: 0.9371 - 69s/epoch - 1ms/step\n",
            "Epoch 14/20\n",
            "60000/60000 - 69s - loss: 0.0099 - accuracy: 0.9430 - val_loss: 0.0107 - val_accuracy: 0.9364 - 69s/epoch - 1ms/step\n",
            "Epoch 15/20\n",
            "60000/60000 - 68s - loss: 0.0098 - accuracy: 0.9435 - val_loss: 0.0106 - val_accuracy: 0.9359 - 68s/epoch - 1ms/step\n",
            "Epoch 16/20\n",
            "60000/60000 - 68s - loss: 0.0096 - accuracy: 0.9453 - val_loss: 0.0104 - val_accuracy: 0.9363 - 68s/epoch - 1ms/step\n",
            "Epoch 17/20\n",
            "60000/60000 - 70s - loss: 0.0094 - accuracy: 0.9461 - val_loss: 0.0104 - val_accuracy: 0.9387 - 70s/epoch - 1ms/step\n",
            "Epoch 18/20\n",
            "60000/60000 - 68s - loss: 0.0093 - accuracy: 0.9469 - val_loss: 0.0107 - val_accuracy: 0.9358 - 68s/epoch - 1ms/step\n",
            "Epoch 19/20\n",
            "60000/60000 - 70s - loss: 0.0092 - accuracy: 0.9471 - val_loss: 0.0105 - val_accuracy: 0.9366 - 70s/epoch - 1ms/step\n",
            "Epoch 20/20\n",
            "60000/60000 - 68s - loss: 0.0091 - accuracy: 0.9481 - val_loss: 0.0101 - val_accuracy: 0.9397 - 68s/epoch - 1ms/step\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Use Stochastic Gradient Descent Function to optimize our loss funciton\n",
        "with learning rate = 0.01\n",
        "'''\n",
        "\n",
        "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Train the model for 20 Epochs and shuffle the order of the inputs\n",
        "# Update weights after each epoch\n",
        "\n",
        "history = model.fit(\n",
        "          train_images, train_labels, \n",
        "          validation_data=(test_images, test_labels),\n",
        "          epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "          verbose=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nueron Saturation\n",
        "\n",
        "tanh and signmoid functions have saturated regions outside of their area of interests causing the gradient descent function to make no change at all for high magnitudes. To overcome this scenario, we can use nonlinear activation funciton to adjust weights to deal its respective gradient descent magnitude. \n",
        "\n",
        "Momentum can be tacked to the current optimizer for faster convergence and to get out of local peaks. Keep in mind that this could cause exploding gradients which can overthow the gradient descent with seemingly large values. Gradient clipping can be used to avoid this scenario."
      ],
      "metadata": {
        "id": "Tgk5aGzLhgWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the model using Adam optimizer which uses adaptive learning rate and momentum."
      ],
      "metadata": {
        "id": "2_zEqO1ZjRWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional Hyper parameters to avoid neuron saturation\n",
        "opt = keras.optimizers.Adam()\n",
        "loss = 'categorical_crossentropy'\n",
        "initializer = keras.initializers.RandomUniform(minval = -0.1, maxval = 0.1)\n",
        "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# Train the model for 20 Epochs and shuffle the order of the inputs\n",
        "# Update weights after each epoch\n",
        "\n",
        "history = model.fit(\n",
        "          train_images, train_labels, \n",
        "          validation_data=(test_images, test_labels),\n",
        "          epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "          verbose=2, shuffle=True)"
      ],
      "metadata": {
        "id": "6fMMkdEqScx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the model using different optimizers"
      ],
      "metadata": {
        "id": "ttF3IG8AjUx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Optimizers = []\n",
        "adaOpt = keras.optimizers.Adagrad(learning_rate=0.01, epsilon=None)\n",
        "RMSPropOpt = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.8, epsilon=None)\n",
        "AdamOpt = keras.optimizers.Adam(learning_rate=0.01, decay=0.0, epsilon=0.1)\n",
        "Optimizers.append(adaOpt)\n",
        "Optimizers.append(RMSPropOpt)\n",
        "Optimizers.append(AdamOpt)\n",
        "\n",
        "# Reducing epochs to test save computational power and time for testing additional hyperparams\n",
        "EPOCHS = 7 \n",
        "lossFunction = ['mean_squared_error', 'categorical_crossentropy']\n",
        "for opt in Optimizers:\n",
        "  for loss in lossFunction:\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "    history = model.fit(\n",
        "          train_images, train_labels, \n",
        "          validation_data=(test_images, test_labels),\n",
        "          epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "          verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "021lz234jWC1",
        "outputId": "402b8d73-b279-4f31-d4f3-de267ee8eedc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "60000/60000 - 81s - loss: 0.0293 - accuracy: 0.9175 - val_loss: 0.0189 - val_accuracy: 0.9233 - 81s/epoch - 1ms/step\n",
            "Epoch 2/7\n",
            "60000/60000 - 81s - loss: 0.0176 - accuracy: 0.9250 - val_loss: 0.0167 - val_accuracy: 0.9219 - 81s/epoch - 1ms/step\n",
            "Epoch 3/7\n",
            "60000/60000 - 79s - loss: 0.0160 - accuracy: 0.9279 - val_loss: 0.0157 - val_accuracy: 0.9249 - 79s/epoch - 1ms/step\n",
            "Epoch 4/7\n",
            "60000/60000 - 90s - loss: 0.0151 - accuracy: 0.9301 - val_loss: 0.0151 - val_accuracy: 0.9245 - 90s/epoch - 2ms/step\n",
            "Epoch 5/7\n",
            "60000/60000 - 81s - loss: 0.0144 - accuracy: 0.9320 - val_loss: 0.0147 - val_accuracy: 0.9265 - 81s/epoch - 1ms/step\n",
            "Epoch 6/7\n",
            "60000/60000 - 80s - loss: 0.0140 - accuracy: 0.9330 - val_loss: 0.0143 - val_accuracy: 0.9274 - 80s/epoch - 1ms/step\n",
            "Epoch 7/7\n",
            "60000/60000 - 78s - loss: 0.0136 - accuracy: 0.9337 - val_loss: 0.0141 - val_accuracy: 0.9265 - 78s/epoch - 1ms/step\n",
            "Epoch 1/7\n",
            "60000/60000 - 91s - loss: 0.2298 - accuracy: 0.9338 - val_loss: 0.2381 - val_accuracy: 0.9303 - 91s/epoch - 2ms/step\n",
            "Epoch 2/7\n",
            "60000/60000 - 79s - loss: 0.2114 - accuracy: 0.9394 - val_loss: 0.2301 - val_accuracy: 0.9340 - 79s/epoch - 1ms/step\n",
            "Epoch 3/7\n",
            "60000/60000 - 79s - loss: 0.2040 - accuracy: 0.9415 - val_loss: 0.2282 - val_accuracy: 0.9350 - 79s/epoch - 1ms/step\n",
            "Epoch 4/7\n",
            "60000/60000 - 79s - loss: 0.1986 - accuracy: 0.9432 - val_loss: 0.2252 - val_accuracy: 0.9342 - 79s/epoch - 1ms/step\n",
            "Epoch 5/7\n",
            "60000/60000 - 90s - loss: 0.1949 - accuracy: 0.9442 - val_loss: 0.2247 - val_accuracy: 0.9359 - 90s/epoch - 1ms/step\n",
            "Epoch 6/7\n",
            "60000/60000 - 77s - loss: 0.1915 - accuracy: 0.9451 - val_loss: 0.2226 - val_accuracy: 0.9347 - 77s/epoch - 1ms/step\n",
            "Epoch 7/7\n",
            "60000/60000 - 77s - loss: 0.1889 - accuracy: 0.9460 - val_loss: 0.2226 - val_accuracy: 0.9352 - 77s/epoch - 1ms/step\n",
            "Epoch 1/7\n",
            "60000/60000 - 123s - loss: 0.0129 - accuracy: 0.9267 - val_loss: 0.0123 - val_accuracy: 0.9295 - 123s/epoch - 2ms/step\n",
            "Epoch 2/7\n",
            "60000/60000 - 94s - loss: 0.0120 - accuracy: 0.9288 - val_loss: 0.0117 - val_accuracy: 0.9316 - 94s/epoch - 2ms/step\n",
            "Epoch 3/7\n",
            "60000/60000 - 89s - loss: 0.0115 - accuracy: 0.9324 - val_loss: 0.0114 - val_accuracy: 0.9323 - 89s/epoch - 1ms/step\n",
            "Epoch 4/7\n",
            "60000/60000 - 102s - loss: 0.0111 - accuracy: 0.9342 - val_loss: 0.0110 - val_accuracy: 0.9340 - 102s/epoch - 2ms/step\n",
            "Epoch 5/7\n",
            "60000/60000 - 91s - loss: 0.0107 - accuracy: 0.9372 - val_loss: 0.0114 - val_accuracy: 0.9329 - 91s/epoch - 2ms/step\n",
            "Epoch 6/7\n",
            "60000/60000 - 89s - loss: 0.0106 - accuracy: 0.9380 - val_loss: 0.0113 - val_accuracy: 0.9345 - 89s/epoch - 1ms/step\n",
            "Epoch 7/7\n",
            "60000/60000 - 88s - loss: 0.0103 - accuracy: 0.9393 - val_loss: 0.0111 - val_accuracy: 0.9329 - 88s/epoch - 1ms/step\n",
            "Epoch 1/7\n",
            "60000/60000 - 90s - loss: 0.4316 - accuracy: 0.9417 - val_loss: 0.3988 - val_accuracy: 0.9380 - 90s/epoch - 2ms/step\n",
            "Epoch 2/7\n",
            "60000/60000 - 87s - loss: 0.3503 - accuracy: 0.9427 - val_loss: 0.3652 - val_accuracy: 0.9388 - 87s/epoch - 1ms/step\n",
            "Epoch 3/7\n",
            "60000/60000 - 87s - loss: 0.3231 - accuracy: 0.9419 - val_loss: 0.3465 - val_accuracy: 0.9379 - 87s/epoch - 1ms/step\n",
            "Epoch 4/7\n",
            "60000/60000 - 93s - loss: 0.3048 - accuracy: 0.9421 - val_loss: 0.3182 - val_accuracy: 0.9352 - 93s/epoch - 2ms/step\n",
            "Epoch 5/7\n",
            "60000/60000 - 90s - loss: 0.2922 - accuracy: 0.9416 - val_loss: 0.3246 - val_accuracy: 0.9350 - 90s/epoch - 2ms/step\n",
            "Epoch 6/7\n",
            "60000/60000 - 87s - loss: 0.2916 - accuracy: 0.9399 - val_loss: 0.3312 - val_accuracy: 0.9355 - 87s/epoch - 1ms/step\n",
            "Epoch 7/7\n",
            "60000/60000 - 88s - loss: 0.2821 - accuracy: 0.9399 - val_loss: 0.3092 - val_accuracy: 0.9344 - 88s/epoch - 1ms/step\n",
            "Epoch 1/7\n",
            "60000/60000 - 104s - loss: 0.0958 - accuracy: 0.8165 - val_loss: 0.0924 - val_accuracy: 0.8172 - 104s/epoch - 2ms/step\n",
            "Epoch 2/7\n",
            "60000/60000 - 99s - loss: 0.0814 - accuracy: 0.7983 - val_loss: 0.0671 - val_accuracy: 0.7220 - 99s/epoch - 2ms/step\n",
            "Epoch 3/7\n",
            "60000/60000 - 111s - loss: 0.0632 - accuracy: 0.6800 - val_loss: 0.0609 - val_accuracy: 0.6652 - 111s/epoch - 2ms/step\n",
            "Epoch 4/7\n",
            "60000/60000 - 104s - loss: 0.0606 - accuracy: 0.6489 - val_loss: 0.0585 - val_accuracy: 0.6430 - 104s/epoch - 2ms/step\n",
            "Epoch 5/7\n",
            "60000/60000 - 99s - loss: 0.0583 - accuracy: 0.6327 - val_loss: 0.0579 - val_accuracy: 0.6437 - 99s/epoch - 2ms/step\n",
            "Epoch 6/7\n",
            "60000/60000 - 102s - loss: 0.0564 - accuracy: 0.6337 - val_loss: 0.0530 - val_accuracy: 0.6409 - 102s/epoch - 2ms/step\n",
            "Epoch 7/7\n",
            "60000/60000 - 104s - loss: 0.0521 - accuracy: 0.6244 - val_loss: 0.0507 - val_accuracy: 0.6240 - 104s/epoch - 2ms/step\n",
            "Epoch 1/7\n",
            "60000/60000 - 100s - loss: 0.5518 - accuracy: 0.8459 - val_loss: 0.4441 - val_accuracy: 0.8693 - 100s/epoch - 2ms/step\n",
            "Epoch 2/7\n",
            "60000/60000 - 101s - loss: 0.4158 - accuracy: 0.8781 - val_loss: 0.3959 - val_accuracy: 0.8861 - 101s/epoch - 2ms/step\n",
            "Epoch 3/7\n",
            "60000/60000 - 109s - loss: 0.3728 - accuracy: 0.8924 - val_loss: 0.3641 - val_accuracy: 0.8959 - 109s/epoch - 2ms/step\n",
            "Epoch 4/7\n",
            "60000/60000 - 100s - loss: 0.3551 - accuracy: 0.8970 - val_loss: 0.3189 - val_accuracy: 0.9097 - 100s/epoch - 2ms/step\n",
            "Epoch 5/7\n",
            "60000/60000 - 101s - loss: 0.3524 - accuracy: 0.8981 - val_loss: 0.3517 - val_accuracy: 0.8938 - 101s/epoch - 2ms/step\n",
            "Epoch 6/7\n",
            "60000/60000 - 100s - loss: 0.3318 - accuracy: 0.9038 - val_loss: 0.3111 - val_accuracy: 0.9128 - 100s/epoch - 2ms/step\n",
            "Epoch 7/7\n",
            "60000/60000 - 100s - loss: 0.3247 - accuracy: 0.9064 - val_loss: 0.3203 - val_accuracy: 0.9069 - 100s/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training our model using best configuration\n",
        "'''\n",
        "Create Sequential models Fully Connected Model\n",
        "- 2 layers: hidden and output layer\n",
        "Input Layer = 784 inputs flattened by 28 x 288 image + 1 bias input \n",
        "Hidden Layer = 25 Inputs\n",
        "Output Layer = 10 Inputs \n",
        "'''\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64  \n",
        "model = keras.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        keras.layers.Dense(25, activation='relu',\n",
        "                          kernel_initializer='he_normal',\n",
        "                          bias_initializer='zeros'),\n",
        "        keras.layers.Dense(10, activation='softmax',\n",
        "                          kernel_initializer='glorot_uniform',\n",
        "                          bias_initializer='zeros')])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "      train_images, train_labels, \n",
        "      validation_data=(test_images, test_labels),\n",
        "      epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
        "      verbose=2, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuyo-dmmmLTO",
        "outputId": "9a0590e7-bd9a-4989-af1f-463d91011445"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "938/938 - 3s - loss: 0.3473 - accuracy: 0.8958 - val_loss: 0.2153 - val_accuracy: 0.9389 - 3s/epoch - 3ms/step\n",
            "Epoch 2/20\n",
            "938/938 - 2s - loss: 0.2007 - accuracy: 0.9424 - val_loss: 0.1827 - val_accuracy: 0.9468 - 2s/epoch - 2ms/step\n",
            "Epoch 3/20\n",
            "938/938 - 2s - loss: 0.1685 - accuracy: 0.9510 - val_loss: 0.1649 - val_accuracy: 0.9498 - 2s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "938/938 - 2s - loss: 0.1453 - accuracy: 0.9574 - val_loss: 0.1532 - val_accuracy: 0.9546 - 2s/epoch - 2ms/step\n",
            "Epoch 5/20\n",
            "938/938 - 2s - loss: 0.1331 - accuracy: 0.9604 - val_loss: 0.1405 - val_accuracy: 0.9592 - 2s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "938/938 - 2s - loss: 0.1215 - accuracy: 0.9640 - val_loss: 0.1444 - val_accuracy: 0.9580 - 2s/epoch - 2ms/step\n",
            "Epoch 7/20\n",
            "938/938 - 2s - loss: 0.1122 - accuracy: 0.9663 - val_loss: 0.1436 - val_accuracy: 0.9581 - 2s/epoch - 2ms/step\n",
            "Epoch 8/20\n",
            "938/938 - 2s - loss: 0.1049 - accuracy: 0.9688 - val_loss: 0.1342 - val_accuracy: 0.9622 - 2s/epoch - 2ms/step\n",
            "Epoch 9/20\n",
            "938/938 - 2s - loss: 0.0983 - accuracy: 0.9704 - val_loss: 0.1400 - val_accuracy: 0.9605 - 2s/epoch - 2ms/step\n",
            "Epoch 10/20\n",
            "938/938 - 2s - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.1419 - val_accuracy: 0.9617 - 2s/epoch - 2ms/step\n",
            "Epoch 11/20\n",
            "938/938 - 2s - loss: 0.0884 - accuracy: 0.9732 - val_loss: 0.1420 - val_accuracy: 0.9588 - 2s/epoch - 2ms/step\n",
            "Epoch 12/20\n",
            "938/938 - 2s - loss: 0.0840 - accuracy: 0.9742 - val_loss: 0.1428 - val_accuracy: 0.9595 - 2s/epoch - 2ms/step\n",
            "Epoch 13/20\n",
            "938/938 - 2s - loss: 0.0811 - accuracy: 0.9750 - val_loss: 0.1419 - val_accuracy: 0.9604 - 2s/epoch - 2ms/step\n",
            "Epoch 14/20\n",
            "938/938 - 2s - loss: 0.0776 - accuracy: 0.9755 - val_loss: 0.1396 - val_accuracy: 0.9629 - 2s/epoch - 2ms/step\n",
            "Epoch 15/20\n",
            "938/938 - 2s - loss: 0.0731 - accuracy: 0.9773 - val_loss: 0.1379 - val_accuracy: 0.9623 - 2s/epoch - 2ms/step\n",
            "Epoch 16/20\n",
            "938/938 - 2s - loss: 0.0711 - accuracy: 0.9780 - val_loss: 0.1414 - val_accuracy: 0.9631 - 2s/epoch - 2ms/step\n",
            "Epoch 17/20\n",
            "938/938 - 2s - loss: 0.0676 - accuracy: 0.9789 - val_loss: 0.1378 - val_accuracy: 0.9645 - 2s/epoch - 2ms/step\n",
            "Epoch 18/20\n",
            "938/938 - 2s - loss: 0.0655 - accuracy: 0.9792 - val_loss: 0.1416 - val_accuracy: 0.9641 - 2s/epoch - 2ms/step\n",
            "Epoch 19/20\n",
            "938/938 - 2s - loss: 0.0630 - accuracy: 0.9805 - val_loss: 0.1474 - val_accuracy: 0.9633 - 2s/epoch - 2ms/step\n",
            "Epoch 20/20\n",
            "938/938 - 2s - loss: 0.0600 - accuracy: 0.9808 - val_loss: 0.1463 - val_accuracy: 0.9623 - 2s/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUl2SY22Xio",
        "outputId": "cdd31df8-cb1b-4fe4-cf41-17d68bb8399d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [0.5518086552619934, 0.4158424735069275, 0.3728443682193756, 0.35512587428092957, 0.35235071182250977, 0.3318481147289276, 0.3247310519218445], 'accuracy': [0.845883309841156, 0.8780999779701233, 0.8924166560173035, 0.8969666957855225, 0.8981166481971741, 0.9038000106811523, 0.9064333438873291], 'val_loss': [0.4441230893135071, 0.3959222137928009, 0.364071786403656, 0.3189278841018677, 0.3516539931297302, 0.3111044764518738, 0.32032835483551025], 'val_accuracy': [0.8693000078201294, 0.8860999941825867, 0.8959000110626221, 0.9096999764442444, 0.8938000202178955, 0.9128000140190125, 0.9068999886512756]}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MNIST-DLL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvypbX2gAK+HTgaXnE4Vm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}